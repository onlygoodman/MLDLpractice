{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "about_transformer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMW5EhM6q+xSIlbOC1kSzUJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onlygoodman/MLDLpractice/blob/master/about_transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6__9YP7Mtaq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import urllib.request\n",
        "import time\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\", filename=\"ChatBotData.csv\")\n",
        "train_data = pd.read_csv('ChatBotData.csv')\n",
        "train_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qgpyHjs2QdLk",
        "outputId": "cb477433-a92b-4648-8ce6-064da0a9c515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Q            A  label\n",
              "0           12시 땡!   하루가 또 가네요.      0\n",
              "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
              "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
              "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
              "4          PPL 심하네   눈살이 찌푸려지죠.      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c125808-029b-4ae1-9653-e497e9ae3cfd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡!</td>\n",
              "      <td>하루가 또 가네요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PPL 심하네</td>\n",
              "      <td>눈살이 찌푸려지죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c125808-029b-4ae1-9653-e497e9ae3cfd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6c125808-029b-4ae1-9653-e497e9ae3cfd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6c125808-029b-4ae1-9653-e497e9ae3cfd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#포지셔널 인코딩"
      ],
      "metadata": {
        "id": "X-afaApFOePt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "\n",
        "    # 배열의 짝수 인덱스(2i)에는 사인 함수 적용\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # 배열의 홀수 인덱스(2i+1)에는 코사인 함수 적용\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    angle_rads = np.zeros(angle_rads.shape)\n",
        "    angle_rads[:, 0::2] = sines\n",
        "    angle_rads[:, 1::2] = cosines\n",
        "    pos_encoding = tf.constant(angle_rads)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "\n",
        "    print(pos_encoding.shape)\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "metadata": {
        "id": "OeKfmzdbOKKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "50 × 128의 크기를 가지는 포지셔널 인코딩 행렬을 시각화하여 어떤 형태를 가지는지 확인해봅시다. 이는 입력 문장의 단어가 50개이면서, 각 단어가 128차원의 임베딩 벡터를 가질 때 사용할 수 있는 행렬입니다."
      ],
      "metadata": {
        "id": "LTgA3L2dOlqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장의 길이 50, 임베딩 벡터의 차원 128\n",
        "sample_pos_encoding = PositionalEncoding(50, 128)\n",
        "\n",
        "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
        "plt.xlabel('Depth')\n",
        "plt.xlim((0, 128))\n",
        "plt.ylabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "-pkvZmi_OcPX",
        "outputId": "9ef76764-71a8-4d47-e5eb-43219bb68000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 50, 128)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 어텐션(Attention)"
      ],
      "metadata": {
        "id": "_vJt5wZgOvy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#5) 스케일드 닷-프로덕트 어텐션 구현하기\n",
        " \n",
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  # query 크기 : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
        "  # key 크기 : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
        "  # value 크기 : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
        "  # padding_mask : (batch_size, 1, 1, key의 문장 길이)\n",
        "\n",
        "  # Q와 K의 곱. 어텐션 스코어 행렬.\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  # 스케일링\n",
        "  # dk의 루트값으로 나눠준다.\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n",
        "  # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n",
        "  # attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "metadata": {
        "id": "GdGYb9ELOxmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    # d_model을 num_heads로 나눈 값.\n",
        "    # 논문 기준 : 64\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    # WQ, WK, WV에 해당하는 밀집층 정의\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    # WO에 해당하는 밀집층 정의\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  # num_heads 개수만큼 q, k, v를 split하는 함수\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # 1. WQ, WK, WV에 해당하는 밀집층 지나기\n",
        "    # q : (batch_size, query의 문장 길이, d_model)\n",
        "    # k : (batch_size, key의 문장 길이, d_model)\n",
        "    # v : (batch_size, value의 문장 길이, d_model)\n",
        "    # 참고) 인코더(k, v)-디코더(q) 어텐션에서는 query 길이와 key, value의 길이는 다를 수 있다.\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # 2. 헤드 나누기\n",
        "    # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
        "    # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
        "    # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    # 3. 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용.\n",
        "    # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
        "    scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
        "    # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # 4. 헤드 연결(concatenate)하기\n",
        "    # (batch_size, query의 문장 길이, d_model)\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    # 5. WO에 해당하는 밀집층 지나기\n",
        "    # (batch_size, query의 문장 길이, d_model)\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "r5_vyargPQFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, key의 문장 길이)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "metadata": {
        "id": "2CAYHOudPopj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "\n",
        "  # 인코더는 패딩 마스크 사용\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  # 멀티-헤드 어텐션 (첫번째 서브층 / 셀프 어텐션)\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
        "          'mask': padding_mask # 패딩 마스크 사용\n",
        "      })\n",
        "\n",
        "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  # 포지션 와이즈 피드 포워드 신경망 (두번째 서브층)\n",
        "  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "metadata": {
        "id": "rsHs5W_wP2ZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder(vocab_size, num_layers, dff,\n",
        "            d_model, num_heads, dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "\n",
        "  # 인코더는 패딩 마스크 사용\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  # 포지셔널 인코딩 + 드롭아웃\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  # 인코더를 num_layers개 쌓기\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
        "        dropout=dropout, name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "metadata": {
        "id": "pyOeHJEuP4F_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 디코더의 첫번째 서브층(sublayer)에서 미래 토큰을 Mask하는 함수\n",
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x) # 패딩 마스크도 포함\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "metadata": {
        "id": "XA3jC1rTQD22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "\n",
        "  # 룩어헤드 마스크(첫번째 서브층)\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "\n",
        "  # 패딩 마스크(두번째 서브층)\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  # 멀티-헤드 어텐션 (첫번째 서브층 / 마스크드 셀프 어텐션)\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
        "          'mask': look_ahead_mask # 룩어헤드 마스크\n",
        "      })\n",
        "\n",
        "  # 잔차 연결과 층 정규화\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  # 멀티-헤드 어텐션 (두번째 서브층 / 디코더-인코더 어텐션)\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1, 'key': enc_outputs, 'value': enc_outputs, # Q != K = V\n",
        "          'mask': padding_mask # 패딩 마스크\n",
        "      })\n",
        "\n",
        "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  # 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n",
        "  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "metadata": {
        "id": "56KaPp7PQH5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder(vocab_size, num_layers, dff,\n",
        "            d_model, num_heads, dropout,\n",
        "            name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "\n",
        "  # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  # 포지셔널 인코딩 + 드롭아웃\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  # 디코더를 num_layers개 쌓기\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
        "        dropout=dropout, name='decoder_layer_{}'.format(i),\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "metadata": {
        "id": "HKCf5rFEQKP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer(vocab_size, num_layers, dff,\n",
        "                d_model, num_heads, dropout,\n",
        "                name=\"transformer\"):\n",
        "\n",
        "  # 인코더의 입력\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "\n",
        "  # 디코더의 입력\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  # 인코더의 패딩 마스크\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "\n",
        "  # 디코더의 룩어헤드 마스크(첫번째 서브층)\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask, output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "\n",
        "  # 디코더의 패딩 마스크(두번째 서브층)\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "  # 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n",
        "  enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
        "      d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n",
        "\n",
        "  # 디코더의 출력은 dec_outputs. 출력층으로 전달된다.\n",
        "  dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
        "      d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  # 다음 단어 예측을 위한 출력층\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "metadata": {
        "id": "8I6IudxBQQB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ],
      "metadata": {
        "id": "cNzjpmaARWYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "metadata": {
        "id": "LLKxzQ6XRbrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 챗봇 실습"
      ],
      "metadata": {
        "id": "9v2-ORyTRLMV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 데이터 로드하기\n"
      ],
      "metadata": {
        "id": "ZLgy401rSILZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions = []\n",
        "for sentence in train_data['Q']:\n",
        "    # 구두점에 대해서 띄어쓰기\n",
        "    # ex) 12시 땡! -> 12시 땡 !\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    questions.append(sentence)"
      ],
      "metadata": {
        "id": "sloJxRGsRfA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers = []\n",
        "for sentence in train_data['A']:\n",
        "    # 구두점에 대해서 띄어쓰기\n",
        "    # ex) 12시 땡! -> 12시 땡 !\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    answers.append(sentence)"
      ],
      "metadata": {
        "id": "KlOBzkMeRiwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.단어집합생성"
      ],
      "metadata": {
        "id": "f5Kc3e2ZRm52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 서브워드텍스트인코더를 사용하여 질문, 답변 데이터로부터 단어 집합(Vocabulary) 생성\n",
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    questions + answers, target_vocab_size=2**13)\n",
        "\n"
      ],
      "metadata": {
        "id": "8hK8XgHjRl16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시작 토큰과 종료 토큰에 대한 정수 부여.\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
        "\n",
        "# 시작 토큰과 종료 토큰을 고려하여 단어 집합의 크기를 + 2\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2"
      ],
      "metadata": {
        "id": "iWMOgpEhRoZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. 정수 인코딩과 패딩\n"
      ],
      "metadata": {
        "id": "CObTuiuyRsxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 서브워드텍스트인코더 토크나이저의 .encode()와 .decode() 테스트해보기\n",
        "# 임의의 입력 문장을 sample_string에 저장\n",
        "sample_string = questions[20]\n",
        "\n",
        "# encode() : 텍스트 시퀀스 --> 정수 시퀀스\n",
        "tokenized_string = tokenizer.encode(sample_string)\n",
        "print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
        "\n",
        "# decode() : 정수 시퀀스 --> 텍스트 시퀀스\n",
        "original_string = tokenizer.decode(tokenized_string)\n",
        "print ('기존 문장: {}'.format(original_string))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bq9oZmUsRvWL",
        "outputId": "a294e032-ea4a-4321-dd3e-272c21d8ae7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정수 인코딩 후의 문장 [5766, 611, 3509, 141, 685, 3747, 849]\n",
            "기존 문장: 가스비 비싼데 감기 걸리겠어\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 정수는 각 단어와 어떻게 mapping되는지 병렬로 출력\n",
        "# 서브워드텍스트인코더는 의미있는 단위의 서브워드로 토크나이징한다. 띄어쓰기 단위 X 형태소 분석 단위 X\n",
        "for ts in tokenized_string:\n",
        "  print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGb1MF5CRzuL",
        "outputId": "adf8efb7-596c-4a81-a8d0-b753d1744753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5766 ----> 가스\n",
            "611 ----> 비 \n",
            "3509 ----> 비싼\n",
            "141 ----> 데 \n",
            "685 ----> 감기 \n",
            "3747 ----> 걸리\n",
            "849 ----> 겠어\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 최대 길이를 40으로 정의\n",
        "MAX_LENGTH = 40\n",
        "\n",
        "# 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩\n",
        "def tokenize_and_filter(inputs, outputs):\n",
        "  tokenized_inputs, tokenized_outputs = [], []\n",
        "\n",
        "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "    # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "\n",
        "    tokenized_inputs.append(sentence1)\n",
        "    tokenized_outputs.append(sentence2)\n",
        "\n",
        "  # 패딩\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
        "\n",
        "  return tokenized_inputs, tokenized_outputs"
      ],
      "metadata": {
        "id": "g36FC0pyR136"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions, answers = tokenize_and_filter(questions, answers)"
      ],
      "metadata": {
        "id": "UP9EBmN1R4jR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. 인코더와 디코더의 입력, 그리고 레이블 만들기.\n"
      ],
      "metadata": {
        "id": "k7TVHzvwR9SC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서플로우 dataset을 이용하여 셔플(shuffle)을 수행하되, 배치 크기로 데이터를 묶는다.\n",
        "# 또한 이 과정에서 교사 강요(teacher forcing)을 사용하기 위해서 디코더의 입력과 실제값 시퀀스를 구성한다.\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거해야 한다.\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': questions,\n",
        "        'dec_inputs': answers[:, :-1] # 디코더의 입력. 마지막 패딩 토큰이 제거된다.\n",
        "    },\n",
        "    {\n",
        "        'outputs': answers[:, 1:]  # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다.\n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "id": "V0vfW3FVR8BB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. 트랜스포머 만들기"
      ],
      "metadata": {
        "id": "P_eCumlBSLD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# 하이퍼파라미터\n",
        "D_MODEL = 256\n",
        "NUM_LAYERS = 2\n",
        "NUM_HEADS = 8\n",
        "DFF = 512\n",
        "DROPOUT = 0.1\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    dff=DFF,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTtcSpX6SSF0",
        "outputId": "857f42f6-7b64-442e-dca8-4eabd27b5e0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 8180, 256)\n",
            "(1, 8180, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  # 레이블의 크기는 (batch_size, MAX_LENGTH - 1)\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "metadata": {
        "id": "w_N94sXTSXd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "model.fit(dataset, epochs=EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlJQ19uqSZ7G",
        "outputId": "c2feaf8a-b473-4713-d612-01b21f76f174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "185/185 [==============================] - 20s 56ms/step - loss: 1.4448 - accuracy: 0.0216\n",
            "Epoch 2/50\n",
            "185/185 [==============================] - 10s 56ms/step - loss: 1.1788 - accuracy: 0.0481\n",
            "Epoch 3/50\n",
            "185/185 [==============================] - 10s 56ms/step - loss: 1.0062 - accuracy: 0.0506\n",
            "Epoch 4/50\n",
            "185/185 [==============================] - 10s 56ms/step - loss: 0.9283 - accuracy: 0.0545\n",
            "Epoch 5/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.8677 - accuracy: 0.0579\n",
            "Epoch 6/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.8076 - accuracy: 0.0623\n",
            "Epoch 7/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.7416 - accuracy: 0.0682\n",
            "Epoch 8/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.6688 - accuracy: 0.0760\n",
            "Epoch 9/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.5897 - accuracy: 0.0845\n",
            "Epoch 10/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.5069 - accuracy: 0.0942\n",
            "Epoch 11/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.4236 - accuracy: 0.1044\n",
            "Epoch 12/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.3434 - accuracy: 0.1151\n",
            "Epoch 13/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.2690 - accuracy: 0.1262\n",
            "Epoch 14/50\n",
            "185/185 [==============================] - 11s 58ms/step - loss: 0.2039 - accuracy: 0.1364\n",
            "Epoch 15/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.1496 - accuracy: 0.1458\n",
            "Epoch 16/50\n",
            "185/185 [==============================] - 11s 58ms/step - loss: 0.1082 - accuracy: 0.1533\n",
            "Epoch 17/50\n",
            "185/185 [==============================] - 11s 58ms/step - loss: 0.0790 - accuracy: 0.1588\n",
            "Epoch 18/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.0607 - accuracy: 0.1620\n",
            "Epoch 19/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.0501 - accuracy: 0.1638\n",
            "Epoch 20/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.0450 - accuracy: 0.1645\n",
            "Epoch 21/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.0426 - accuracy: 0.1649\n",
            "Epoch 22/50\n",
            "185/185 [==============================] - 11s 58ms/step - loss: 0.0402 - accuracy: 0.1652\n",
            "Epoch 23/50\n",
            "185/185 [==============================] - 11s 58ms/step - loss: 0.0359 - accuracy: 0.1660\n",
            "Epoch 24/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.0317 - accuracy: 0.1673\n",
            "Epoch 25/50\n",
            "185/185 [==============================] - 11s 59ms/step - loss: 0.0270 - accuracy: 0.1684\n",
            "Epoch 26/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.0245 - accuracy: 0.1689\n",
            "Epoch 27/50\n",
            "185/185 [==============================] - 10s 57ms/step - loss: 0.0216 - accuracy: 0.1697\n",
            "Epoch 28/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.0201 - accuracy: 0.1701\n",
            "Epoch 29/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.0182 - accuracy: 0.1707\n",
            "Epoch 30/50\n",
            "185/185 [==============================] - 11s 58ms/step - loss: 0.0167 - accuracy: 0.1710\n",
            "Epoch 31/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.0156 - accuracy: 0.1712\n",
            "Epoch 32/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.0143 - accuracy: 0.1715\n",
            "Epoch 33/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.0135 - accuracy: 0.1718\n",
            "Epoch 34/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.0120 - accuracy: 0.1721\n",
            "Epoch 35/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.0115 - accuracy: 0.1724\n",
            "Epoch 36/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.0110 - accuracy: 0.1725\n",
            "Epoch 37/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.0106 - accuracy: 0.1725\n",
            "Epoch 38/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.0095 - accuracy: 0.1728\n",
            "Epoch 39/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.0086 - accuracy: 0.1730\n",
            "Epoch 40/50\n",
            "185/185 [==============================] - 11s 58ms/step - loss: 0.0085 - accuracy: 0.1731\n",
            "Epoch 41/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.0079 - accuracy: 0.1732\n",
            "Epoch 42/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.0078 - accuracy: 0.1733\n",
            "Epoch 43/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.0075 - accuracy: 0.1733\n",
            "Epoch 44/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.0073 - accuracy: 0.1733\n",
            "Epoch 45/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.0069 - accuracy: 0.1734\n",
            "Epoch 46/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.0068 - accuracy: 0.1735\n",
            "Epoch 47/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.0061 - accuracy: 0.1736\n",
            "Epoch 48/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.0060 - accuracy: 0.1736\n",
            "Epoch 49/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.0061 - accuracy: 0.1736\n",
            "Epoch 50/50\n",
            "185/185 [==============================] - 11s 57ms/step - loss: 0.0059 - accuracy: 0.1737\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4630e31890>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. 챗봇 평가하기"
      ],
      "metadata": {
        "id": "3sCPHPneSbam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sentence(sentence):\n",
        "  # 단어와 구두점 사이에 공백 추가.\n",
        "  # ex) 12시 땡! -> 12시 땡 !\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "  sentence = sentence.strip()\n",
        "  return sentence"
      ],
      "metadata": {
        "id": "hyD9Uqa3SdWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(sentence):\n",
        "  # 입력 문장에 대한 전처리\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  # 입력 문장에 시작 토큰과 종료 토큰을 추가\n",
        "  sentence = tf.expand_dims(\n",
        "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "\n",
        "  output = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "  # 디코더의 예측 시작\n",
        "  for i in range(MAX_LENGTH):\n",
        "    predictions = model(inputs=[sentence, output], training=False)\n",
        "\n",
        "    # 현재 시점의 예측 단어를 받아온다.\n",
        "    predictions = predictions[:, -1:, :]\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # 만약 현재 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
        "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "      break\n",
        "\n",
        "    # 현재 시점의 예측 단어를 output(출력)에 연결한다.\n",
        "    # output은 for문의 다음 루프에서 디코더의 입력이 된다.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  # 단어 예측이 모두 끝났다면 output을 리턴.\n",
        "  return tf.squeeze(output, axis=0)"
      ],
      "metadata": {
        "id": "eN3HuydGSe0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(sentence):\n",
        "  prediction = evaluate(sentence)\n",
        "\n",
        "  # prediction == 디코더가 리턴한 챗봇의 대답에 해당하는 정수 시퀀스\n",
        "  # tokenizer.decode()를 통해 정수 시퀀스를 문자열로 디코딩.\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "  print('Input: {}'.format(sentence))\n",
        "  print('Output: {}'.format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence"
      ],
      "metadata": {
        "id": "zJafV2L_Sf8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(\"안녕 오늘 날씨가 좋다\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "F4EQQVJwrZII",
        "outputId": "408933b3-c471-4d92-9e06-38b17b3454da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: 안녕 오늘 날씨가 좋다\n",
            "Output: 사적 영역에 깊숙이 들어가보세요 .\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'사적 영역에 깊숙이 들어가보세요 .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sum_all(start, end):\n",
        "  output=0\n",
        "\n",
        "  for i in range(start, end+1):\n",
        "    output+=i\n",
        "  return output\n",
        "\n",
        "print(\"0부터 100까지 더하면 : {}이다.\".format(sum_all(0,100)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZmQAnrGQtMT",
        "outputId": "e2297644-7b8d-462c-85cd-2a658037c29a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0부터 100까지 더하면 : 5050이다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n=3\n",
        "\n",
        "slist=[\"KOREAKOREAKOREAKOREAKOREAKOREA\",\"SAMSUNGSAMSUNGSAMSUNGSAMSUNGSA\",\"GALAXYGALAXYGALAXYGALAXYGALAXY\"]\n",
        "\n",
        "sendic={}\n",
        "for x in range(n):\n",
        "\n",
        "  for i in range(1, 10+1):\n",
        "    if slist[x].count(slist[x][0:i])==30//i:\n",
        "      print(\"#{} {}\".format(x+1,i))\n",
        "      break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5DGDLmOkxcD",
        "outputId": "865cee26-4bbd-4c62-fc5a-ea5cbe06ca93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#1 5\n",
            "#2 7\n",
            "#3 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for j in range(5, 25+1, 5):\n",
        "  if sen[0:5]==sen[j:j+5]:\n",
        "    continue\n",
        "  else:\n",
        "    break\n",
        "  sendic[sen]=i\n",
        "print(sendic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cd21YhK0m5aZ",
        "outputId": "b77e82aa-4b8a-41f5-f028-012c45163bee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=\"ababababaa\"\n",
        "print(x[1:3])\n",
        "x.count(\"ab\",30//5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLupIFS6l2hh",
        "outputId": "1e8a8188-1617-4116-a41c-72a2b00d68d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ba\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sen=input()\n",
        "\n",
        "x=len(sen)//10\n",
        "y=len(sen)%10\n",
        "\n",
        "for i in range(x):\n",
        "    print(sen[i*10:(i+1)*10])\n",
        "    \n",
        "if y!=0:\n",
        "    print(sen[x*10:len(sen)+y])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JfWPASxwHO1",
        "outputId": "abaa4570-bd92-4a98-ce81-4f660ad57845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OneTwoThreeFourFiveSixSevenEightNineTen\n",
            "OneTwoThre\n",
            "eFourFiveS\n",
            "ixSevenEig\n",
            "htNineTen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcHP9IX4wODK",
        "outputId": "6330dc48-cac4-41fc-9158-a1d71ac580eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word=input()\n",
        "answer=\"\"\n",
        "for i in word:\n",
        "  if i==i.upper():\n",
        "    answer+=i.lower()\n",
        "\n",
        "  elif i!=i.upper():\n",
        "    answer+=i.upper()\n",
        "\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qb0DPRAw-z9",
        "outputId": "ea9dea52-dd32-47e8-c0c2-3897a02ae629"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WrongAnswer\n",
            "wRONGaNSWER\n"
          ]
        }
      ]
    }
  ]
}